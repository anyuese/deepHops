#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import division, unicode_literals
import argparse

from graph_embedding import init_condition_transformer
from onmt.utils.logging import init_logger
from onmt.translate.translator import build_translator

import onmt.inputters
import onmt.translate
import onmt
import onmt.model_builder
import onmt.modules
import onmt.opts
from split_data import TASKS, include_list
import os

def translating_opt_postprocessing(opt):
    if opt.rnn_size != -1:
        opt.enc_rnn_size = opt.rnn_size

        if opt.arch in ['transformer', 'after_encoding']:
            opt.dec_rnn_size = opt.rnn_size + opt.condition_dim
        else:
            opt.dec_rnn_size = opt.rnn_size
            if opt.model_type == 'text' and opt.enc_rnn_size != opt.dec_rnn_size:
                raise AssertionError("""We do not support different encoder and
                                     decoder rnn sizes for translation now.""")

    return opt

def main(opt):
    # 初始化口袋特征编码器
    init_condition_transformer(opt.use_graph_embedding, opt.condition_dim)
    base_dir = os.path.dirname(opt.output)
    os.makedirs(base_dir, exist_ok=True)
    src_path = f"{base_dir}/src-test-protein.txt"
    # tgt_path = f"{base_dir}/tgt-test-protein.txt"
    cond_path = f"{base_dir}/cond-test-protein.txt"
    if opt.proteins is not None and len(opt.proteins) > 0 and not os.path.isfile(src_path) and not os.path.isfile(cond_path):
        with open(opt.cond) as reader:
            cond_lines = [[i, int(s.rstrip())] for i, s in enumerate(reader.readlines())]
        protein_list = [TASKS.index(s) for s in opt.proteins]
        line_index = [i for i, v in cond_lines if v in protein_list]

        with open(opt.src) as reader:
            lines = reader.readlines()
            src_list = [lines[i] for i in line_index]
        with open(opt.cond) as reader:
            lines = reader.readlines()
            cond_list = [lines[i] for i in line_index]

        uniq_set = set([f"{smi}_{cond}" for smi, cond in zip(src_list, cond_list)])
        with open(src_path, 'w') as src_writer, open(cond_path, 'w') as writer:
            for v in uniq_set:
                smi, cond = v.split('_')
                src_writer.writelines([smi])
                writer.writelines([cond])
    opt.src = src_path
    # opt.tgt = tgt_path
    opt.cond = cond_path
    translator = build_translator(opt, report_score=True)
    translator.translate(src_path=opt.src,
                         tgt_path=opt.tgt,
                         src_dir=opt.src_dir,
                         batch_size=opt.batch_size,
                         attn_debug=opt.attn_debug,
                         condition_path=opt.cond,
                         prepare_pt_file=opt.prepare_pt_file,
                         opt = opt)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='translate.py',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    onmt.opts.add_md_help_argument(parser)
    onmt.opts.translate_opts(parser)

    group = parser.add_argument_group('fulmz_ext')
    group.add_argument('-proteins', nargs='+', type=str,
                       help='translate the molecules of proteins in test data')
    group.add_argument('-use_protein40', action='store_true', default=False,
                       help='translate the molecules of forty proteins(all proteins in training set) in test data')
    group.add_argument('-use_graph_embedding', action='store_true', default=False,
                       help='if false, using the onehot encoding as the embedding of protein, '
                            'else use embedding generated by ProteinBertModel')
    group.add_argument('-condition_dim', type=int, default=0, help='embedding size of protein')
    group.add_argument('-arch', type=str, default='before_linear', choices=['before_linear', 'after_encoding', 'after_decoding', 'no_cond', 'transformer'],
                       help='model architecture')
    group.add_argument('-prepare_pt_file', type=str, help='the cache directory of preprared data')
    group.add_argument('-with_3d_confomer', action='store_true', default=False, help='Searching conformation of molecule to get the 3D positions of atoms per molecule,the position is required by Graph3dConv')
    opt = parser.parse_args()
    if opt.use_protein40:
        opt.proteins = list(include_list)

    logger = init_logger(opt.log_file)
    main(opt)
